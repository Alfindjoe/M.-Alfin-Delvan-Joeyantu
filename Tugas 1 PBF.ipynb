{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO7B7rLH8C7l"
      },
      "outputs": [],
      "source": [
        "# Alpina Damayanti Program main1_120450024.py\n",
        "# Author : M. Alfin Delvan Joeyantu\n",
        "# NIM : 120450024\n",
        "# Kelas : RB\n",
        "# Affiliation : Sains Data ITERA\n",
        "# Date : 30th march 2022\n",
        "# Program Description : Program to solve simple encryption password problem (case 1)\n",
        "\n",
        "# a. Bantulah user tersebut dengan membuatkan sebuah program yang secara otomatis mengubah password yang di input menjadi terenkripsi sesuai aturan tersebut!\n",
        "def encrypt(plaintext):\n",
        "    \"\"\"encrypt encrypts given plaintext into a ciphertext.\"\"\"\n",
        "    if len(plaintext) > 100:\n",
        "        raise \"plaintext must be less than 100 characters\"\n",
        "\n",
        "    # cache computed token.\n",
        "    computed = {}\n",
        "\n",
        "    words = []\n",
        "    for char in plaintext:\n",
        "        if char not in computed:\n",
        "            unicode_number = ord(char)\n",
        "            token = tokenize(unicode_number)\n",
        "            word = token_to_string(token)\n",
        "            # store the word of token for later use.\n",
        "            computed[char] = word\n",
        "\n",
        "        # simple optimization.\n",
        "        # reuse computed word of token.\n",
        "        words.append(computed[char])\n",
        "\n",
        "    return join_chars(words)\n",
        "\n",
        "\n",
        "def encrypt_functional(plaintext):\n",
        "    \"\"\"encrypt_functional is a functional version of encrypt.\"\"\"\n",
        "    # notes: please read from innermost([1]) to outermost([3]).\n",
        "    words = map(\n",
        "        # [3] maps each token into a string representation.\n",
        "        lambda token: token_to_string(token),\n",
        "        map(\n",
        "            # [2] maps each unicode into token.\n",
        "            lambda unicode: tokenize(unicode),\n",
        "            map(\n",
        "                # [1] maps each character in plaintext into each unicode.\n",
        "                lambda char: ord(char),\n",
        "                list(plaintext),\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return join_chars(words)\n",
        "\n",
        "\n",
        "def decrypt(ciphertext):\n",
        "    \"\"\"decrypt decrypts given ciphertext into a plaintext.\"\"\"\n",
        "    chars = []\n",
        "\n",
        "    tokens = string_to_tokens(ciphertext)\n",
        "    for token in tokens:\n",
        "        unicode_number = detokenize(token)\n",
        "        char = chr(unicode_number)\n",
        "        chars.append(char)\n",
        "\n",
        "    return join_chars(chars)\n",
        "\n",
        "\n",
        "def decrypt_functional(ciphertext):\n",
        "    \"\"\"decrypt_functional is a functional version of decrypt.\"\"\"\n",
        "    # notes: please read from innermost([1]) to outermost([2]).\n",
        "    chars = map(\n",
        "        # [1] maps each unicode into character.\n",
        "        lambda unicode: chr(unicode),\n",
        "        map(\n",
        "            # [2] converts each token into unicode.\n",
        "            lambda token: detokenize(token),\n",
        "            string_to_tokens(ciphertext),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return join_chars(chars)\n",
        "\n",
        "\n",
        "def tokenize(n):\n",
        "    \"\"\"tokenize transforms an integer n into a token (3-column tuple of integers).\n",
        "    >>> tokenize(52) == (82, 81, 45)\n",
        "    True\n",
        "    \"\"\"\n",
        "\n",
        "    if n <= 0:\n",
        "        raise \"n must be a positive number\"\n",
        "\n",
        "    a = n // 26 + 80\n",
        "    b = n % 26 + 80\n",
        "    c = ord('-') if a > b else ord('+')\n",
        "\n",
        "    return a, b, c\n",
        "\n",
        "\n",
        "def detokenize(token):\n",
        "    \"\"\"detokenize is an inverse of the tokenize function. Detokenize takes a token and returns the original n.\n",
        "    >>> detokenize((82, 81, 45)) == 52\n",
        "    True\n",
        "    \"\"\"\n",
        "\n",
        "    if len(token) != 3:\n",
        "        raise \"token must be has exactly 3 items\"\n",
        "\n",
        "    # unpacks token tuple.\n",
        "    (a, b, _) = token\n",
        "\n",
        "    if a < 0 or b < 0:\n",
        "        raise \"each item in token must be a positive number\"\n",
        "\n",
        "    rev_a = (a - 80) * 26\n",
        "    rev_b = (b - 80)  # we can ignore the module inverse\n",
        "\n",
        "    return rev_a + rev_b\n",
        "\n",
        "\n",
        "def token_to_string(token):\n",
        "    \"\"\"token_to_string returns a string representation of given token\"\"\"\n",
        "    if len(token) != 3:\n",
        "        raise \"token must be 3-column tuple\"\n",
        "\n",
        "    (a, b, c) = token\n",
        "\n",
        "    return \"{0}{1}{2}\".format(chr(a), chr(b), chr(c))\n",
        "\n",
        "\n",
        "def string_to_token(s):\n",
        "    \"\"\"string_to_token returns a token representation of a given s\"\"\"\n",
        "    if len(s) < 3:\n",
        "        raise \"string must be at least 3 characters\"\n",
        "\n",
        "    a = ord(s[0])\n",
        "    b = ord(s[1])\n",
        "    c = ord(s[2])\n",
        "\n",
        "    return a, b, c\n",
        "\n",
        "\n",
        "def string_to_tokens(s):\n",
        "    \"\"\"string_to_tokens transform given s with length L into list of token with length L/3\"\"\"\n",
        "\n",
        "    if len(s) % 3 != 0:\n",
        "        raise \"length of s must be dividable by 3\"\n",
        "\n",
        "    # cache computed token.\n",
        "    computed = {}\n",
        "\n",
        "    tokens = []\n",
        "    for i in range(0, len(s), 3):\n",
        "        substring = s[i:i + 3]\n",
        "        if substring not in computed:\n",
        "            token = string_to_token(substring)\n",
        "            computed[substring] = token\n",
        "            tokens.append(token)\n",
        "        else:\n",
        "            tokens.append(computed[substring])\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def join_chars(chars):\n",
        "    \"\"\"join_chars combines list of character into a word\"\"\"\n",
        "    return \"\".join(chars)\n",
        "\n",
        "# b. Apa output yang dihasilkan dari program tersebut jika input password adalah ‘anakanakcerdas2020’ ?\n",
        "plaintext = \"anakanakcerdas2020\"\n",
        "ciphertext = encrypt(plaintext)\n",
        "decrypted = decrypt(ciphertext)\n",
        "print(\"ciphertext:\", ciphertext)\n",
        "print(\"plaintext :\", decrypted)\n",
        "\n",
        "# c. (Bonus) User tersebut lupa password asli yang dia inputkan ke dalam program tersebut, password setelah dienkripsi adalah ‘Sc-TV-Sc-TS+T[-Sc-TQ+TV-T[-Sf-Sc-T\\-Sc-Qh-Qf-Qh-Qf-TS+Sg-Se-Sg-’. Bantulah user tersebut mendapatkan password asli nya!\n",
        "text = 'Sc+TV+Sc+TS-T[+Sc+TQ-TV+T[+Sf+Sc+T\\+Sc+Qh+Qf+Qh+Qf+TS-Sg+Se+Sg+'\n",
        "print('encrypted password :', text)\n",
        "print('decrypted password :', decrypt(text))"
      ]
    }
  ]
}